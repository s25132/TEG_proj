import os
import requests
import streamlit as st

# URL backendu FastAPI
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000")


def ask_backend(question: str, top_k: int = 5):
    """WysyÅ‚a pytanie do backendu /ask_rag i zwraca odpowiedÅº + kontekst."""
    url = f"{BACKEND_URL}/ask_rag"
    payload = {"question": question, "top_k": top_k}

    resp = requests.post(url, json=payload, timeout=60)
    resp.raise_for_status()
    data = resp.json()
    return data["answer"], data.get("context_documents", [])


def ask_backend_graph(question: str, top_k: int = 5):
    """WysyÅ‚a pytanie do backendu /ask_graph (Graph RAG) i zwraca odpowiedÅº + kontekst grafowy."""
    url = f"{BACKEND_URL}/ask_graph"
    payload = {"question": question, "top_k": top_k}

    resp = requests.post(url, json=payload, timeout=60)
    resp.raise_for_status()
    data = resp.json()
    return data["answer"], data.get("context_subgraphs", [])


def upload_rfp(file) -> str:
    """WysyÅ‚a PDF do backendu /add_rfp."""
    url = f"{BACKEND_URL}/add_rfp"
    files = {"file": (file.name, file.getvalue(), "application/pdf")}
    resp = requests.post(url, files=files, timeout=60)
    resp.raise_for_status()
    data = resp.json()
    return data.get("status", "UNKNOWN")


# --- UI ---

st.set_page_config(page_title="Talent AI", page_icon="ğŸ’¬", layout="centered")
st.title("Talent AI")

# Sidebar
with st.sidebar:
    st.header("Ustawienia")
    backend = st.text_input("Backend URL", value=BACKEND_URL)

BACKEND_URL = backend

# --- Kontrola aktywnej zakÅ‚adki ---

TAB_OPTIONS = ["chat", "graph", "rfp"]  # â†’ RFP jako ostatnia
tab_choice = st.session_state.get("active_tab", "chat")

selected_tab = st.radio(
    "Wybierz zakÅ‚adkÄ™:",
    ["ğŸ’¬ Chat", "ğŸ•¸ï¸ Graph", "ğŸ“„ Dodaj RFP (PDF)"],  # kolejnoÅ›Ä‡ zgodna z wymaganiem
    horizontal=True
)

label_to_key = {
    "ğŸ’¬ Chat": "chat",
    "ğŸ•¸ï¸ Graph": "graph",
    "ğŸ“„ Dodaj RFP (PDF)": "rfp",
}

current_tab_key = label_to_key[selected_tab]

# Reset historii tylko przy zmianie zakÅ‚adki
if current_tab_key != tab_choice:
    st.session_state["messages"] = []
    st.session_state["active_tab"] = current_tab_key

if "messages" not in st.session_state:
    st.session_state["messages"] = []


# --- ZakÅ‚adka Chat (tekstowy RAG) ---

if current_tab_key == "chat":
    st.header("ğŸ’¬ Chat")

    top_k = st.slider("Liczba dokumentÃ³w (top_k)", 1, 10, 5)

    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_input = st.chat_input("Zadaj pytanie o projekty lub CV...")

    if user_input:
        st.session_state["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        try:
            with st.chat_message("assistant"):
                with st.spinner("MyÅ›lÄ™..."):
                    answer, context_docs = ask_backend(user_input, top_k=top_k)
                    st.markdown(answer)

                    if context_docs:
                        with st.expander("PokaÅ¼ uÅ¼yty kontekst (dokumenty z Chroma)"):
                            for i, doc in enumerate(context_docs, start=1):
                                st.markdown(f"**Dokument {i}:**")
                                st.write(doc)
                                st.markdown("---")

            st.session_state["messages"].append({"role": "assistant", "content": answer})

        except requests.RequestException as e:
            err = f"BÅ‚Ä…d komunikacji z backendem: {e}"
            st.error(err)
            st.session_state["messages"].append({"role": "assistant", "content": err})


# --- ZakÅ‚adka Graph (Graph RAG) ---

if current_tab_key == "graph":
    st.header("ğŸ•¸ï¸ Graph RAG")

    top_k = st.slider("Liczba elementÃ³w grafu (top_k)", 1, 10, 5)

    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_input = st.chat_input("Zadaj pytanie do grafowej bazy wiedzy...")

    if user_input:
        st.session_state["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        try:
            with st.chat_message("assistant"):
                with st.spinner("AnalizujÄ™ graf..."):
                    answer, context_subgraphs = ask_backend_graph(user_input, top_k=top_k)
                    st.markdown(answer)

                    if context_subgraphs:
                        with st.expander("PokaÅ¼ uÅ¼yty kontekst grafowy (podgrafy / Å›cieÅ¼ki)"):
                            for i, sg in enumerate(context_subgraphs, start=1):
                                st.markdown(f"**Podgraf {i}:**")
                                st.write(sg)
                                st.markdown("---")

            st.session_state["messages"].append({"role": "assistant", "content": answer})

        except requests.RequestException as e:
            err = f"BÅ‚Ä…d komunikacji z backendem (Graph): {e}"
            st.error(err)
            st.session_state["messages"].append({"role": "assistant", "content": err})


# --- ZakÅ‚adka RFP (ostatnia) ---

if current_tab_key == "rfp":
    st.header("ğŸ“„ Dodaj nowe RFP (PDF)")

    uploaded_file = st.file_uploader("Wybierz plik PDF:", type=["pdf"])

    if uploaded_file is not None:
        st.write(f"Wybrano: **{uploaded_file.name}**")

        if st.button("WyÅ›lij do backendu"):
            try:
                with st.spinner("WysyÅ‚am plik..."):
                    status = upload_rfp(uploaded_file)
                st.success(f"Status backendu: {status}")
            except requests.RequestException as e:
                st.error(f"âŒ BÅ‚Ä…d podczas wysyÅ‚ania: {e}")
